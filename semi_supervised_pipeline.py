# -*- coding: utf-8 -*-
"""Difussion_Models_Mini_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HeQ0_okYpPyKEO6Eed08vApvHfrCFn6u
"""

!pip install torch torchvision

import torch
import torchvision
import torch.nn as nn
import matplotlib.pyplot as plt

dataset = torchvision.datasets.MNIST(root="./data", train=True, download=True , transform=torchvision.transforms.ToTensor())

img, _= dataset[0]

# Now Add Gussian Noise
def add_noise(img , t, noise_level = 0.1):
  noise = torch.randn_like(img) * t * noise_level
  return img + noise

fig , axes = plt.subplots(1,5, figsize=(10,2))
for i , t in enumerate([1,2,4,6,8]):
  noise = add_noise(img=img, t=t)
  axes[i].imshow(noise.squeeze(), cmap="gray")
  axes[i].set_title(f"t={t}")
plt.show()

import torch.nn as nn

class SimpleUNet(nn.Module):
    def __init__(self):
        super(SimpleUNet, self).__init__()
        # Encoder Path
        self.enc1 = nn.Conv2d(1, 16, 3, padding=1)  # Encoder conv1: 1 input channel (e.g., grayscale image), 16 output channels, 3x3 kernel, 1 pixel padding
        self.enc2 = nn.Conv2d(16, 32, 3, padding=1) # Encoder conv2: 16 input channels, 32 output channels, 3x3 kernel, 1 pixel padding

        # Decoder Path
        # This decodes (upsamples) the feature map from enc2
        self.dec1 = nn.ConvTranspose2d(32, 16, 2, stride=2) # Decoder (upsampling): 32 input channels, 16 output channels, 2x2 kernel, stride of 2 for upsampling

        # Output Layer
        # This layer produces the final output with the desired number of channels (e.g., 1 for binary segmentation)
        self.out = nn.Conv2d(16, 1, 1) # Output conv: 16 input channels, 1 output channel, 1x1 kernel

    def forward(self, x):
        x1 = F.relu(self.enc1(x))
        x2 = F.relu(self.enc2(F.max_pool2d(x1, 2)))
        x3 = F.relu(self.dec1(x2))
        return torch.sigmoid(self.out(x3))

# Now implement pseudo labels

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset, random_split
import torchvision
import torchvision.transforms as T
import matplotlib.pyplot as plt



labeled_size = 200
unlabeled_size = 1000
labeled_set, unlabeled_set, _ = random_split(dataset, [labeled_size, unlabeled_size, len(dataset)-labeled_size-unlabeled_size])

labeled_loader = DataLoader(labeled_set, batch_size=16, shuffle=True)
unlabeled_loader = DataLoader(unlabeled_set, batch_size=16, shuffle=False)

device = "cuda" if torch.cuda.is_available() else "cpu"
model = SimpleUNet().to(device)

criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)


# -----------------------------
# 3. Train on labeled data only
# -----------------------------
print("Step 1: Training on small labeled set...")
for epoch in range(3):
    for imgs, labels in labeled_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        masks = (imgs > 0.5).float()

        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
    print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")


# -----------------------------
# 4. Generate pseudo-labels
# -----------------------------
@torch.no_grad()
def get_pseudo_labels(model, loader, device="cpu", conf_threshold=0.7):
    model.eval()
    pseudo_dataset = []
    for imgs, _ in loader:
        imgs = imgs.to(device)
        probs = model(imgs)
        pseudo = (probs > 0.5).float()
        conf = torch.maximum(probs, 1 - probs)
        mask = (conf >= conf_threshold).float()
        pseudo_dataset.append((imgs.cpu(), pseudo.cpu(), mask.cpu()))
    return pseudo_dataset

pseudo_data = get_pseudo_labels(model, unlabeled_loader, device=device)


# -----------------------------
# 5. Custom dataset mixing real + pseudo labels
# -----------------------------
class SemiSupervisedDataset(Dataset):
    def __init__(self, labeled_set, pseudo_data):
        self.labeled_set = labeled_set
        self.pseudo_data = pseudo_data

    def __len__(self):
        return len(self.labeled_set) + sum(len(batch[0]) for batch in self.pseudo_data)

    def __getitem__(self, idx):
        # real labeled samples first
        if idx < len(self.labeled_set):
            img, label = self.labeled_set[idx]
            img = img
            mask = (img > 0.5).float()
            weight = torch.ones_like(mask)  # fully trusted
        else:
            # pseudo labeled samples
            offset = idx - len(self.labeled_set)
            batch_id = 0
            while offset >= len(self.pseudo_data[batch_id][0]):
                offset -= len(self.pseudo_data[batch_id][0])
                batch_id += 1
            img = self.pseudo_data[batch_id][0][offset]
            mask = self.pseudo_data[batch_id][1][offset]
            weight = self.pseudo_data[batch_id][2][offset]
        return img, mask, weight


semi_dataset = SemiSupervisedDataset(labeled_set, pseudo_data)
semi_loader = DataLoader(semi_dataset, batch_size=16, shuffle=True)


# -----------------------------
# 6. Semi-supervised training loop
# -----------------------------
print("\nStep 2: Training on real + pseudo labels...")
for epoch in range(3):
    for imgs, masks, weights in semi_loader:
        imgs, masks, weights = imgs.to(device), masks.to(device), weights.to(device)

        optimizer.zero_grad()
        outputs = model(imgs)

        # weighted loss (real=1, pseudo = confidence)
        loss = ((criterion(outputs, masks) * weights).mean())
        loss.backward()
        optimizer.step()
    print(f"Semi-Supervised Epoch {epoch+1}, Loss: {loss.item():.4f}")


# -----------------------------
# 7. Visualize some predictions
# -----------------------------
imgs, masks, weights = next(iter(semi_loader))
with torch.no_grad():
    preds = model(imgs.to(device)).cpu()

fig, axes = plt.subplots(1, 3, figsize=(9,3))
axes[0].imshow(imgs[0,0], cmap="gray"); axes[0].set_title("Input")
axes[1].imshow(masks[0,0], cmap="gray"); axes[1].set_title("Mask")
axes[2].imshow(preds[0,0], cmap="gray"); axes[2].set_title("Prediction")
plt.show()



